Lmod Warning: The environment MODULEPATH has been changed in unexpected ways.
Lmod is unable to use given MODULEPATH. It is using:

"/sw/modules/all".

Please use "module use ..." to change MODULEPATH instead. 


2022-08-10 03:54:47.413256: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2022-08-10 03:54:47.445387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-08-10 03:54:47.445674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.755GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-08-10 03:54:47.446201: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2022-08-10 03:54:47.448164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2022-08-10 03:54:47.449512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2022-08-10 03:54:47.450159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2022-08-10 03:54:47.451550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2022-08-10 03:54:47.452580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2022-08-10 03:54:47.455025: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2022-08-10 03:54:47.455091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-08-10 03:54:47.455396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-08-10 03:54:47.455648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2022-08-10 03:54:47.455832: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2022-08-10 03:54:47.459175: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3600000000 Hz
2022-08-10 03:54:47.459242: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f58fc000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-08-10 03:54:47.459248: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-08-10 03:54:47.552480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-08-10 03:54:47.552781: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a07af12060 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-08-10 03:54:47.552788: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2022-08-10 03:54:47.552893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-08-10 03:54:47.553139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.755GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2022-08-10 03:54:47.553171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2022-08-10 03:54:47.553180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2022-08-10 03:54:47.553188: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2022-08-10 03:54:47.553196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2022-08-10 03:54:47.553204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2022-08-10 03:54:47.553211: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2022-08-10 03:54:47.553219: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2022-08-10 03:54:47.553249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-08-10 03:54:47.553505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-08-10 03:54:47.553738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2022-08-10 03:54:47.553756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2022-08-10 03:54:47.554084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-10 03:54:47.554091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2022-08-10 03:54:47.554095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2022-08-10 03:54:47.554147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-08-10 03:54:47.554410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-08-10 03:54:47.554659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10208 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
Using TensorFlow backend.
---------CREATE DATA GENERATOR---------
all: 15233  batch per epoch 238
all: 22180  batch per epoch 346
---------COMPILE MODEL---------
---------INIT CALLBACK---------
---------FITTING---------
Epoch 1/90
Traceback (most recent call last):
  File "train.py", line 64, in <module>
    model.fit_generator(generator=train_gen,
  File "/home/nnmkhoi/miniconda3/envs/fsd/lib/python3.8/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/nnmkhoi/miniconda3/envs/fsd/lib/python3.8/site-packages/keras/engine/training.py", line 1718, in fit_generator
    return training_generator.fit_generator(
  File "/home/nnmkhoi/miniconda3/envs/fsd/lib/python3.8/site-packages/keras/engine/training_generator.py", line 217, in fit_generator
    outs = model.train_on_batch(x, y,
  File "/home/nnmkhoi/miniconda3/envs/fsd/lib/python3.8/site-packages/keras/engine/training.py", line 1505, in train_on_batch
    x, y, sample_weights = self._standardize_user_data(
  File "/home/nnmkhoi/miniconda3/envs/fsd/lib/python3.8/site-packages/keras/engine/training.py", line 616, in _standardize_user_data
    y = training_utils.standardize_input_data(
  File "/home/nnmkhoi/miniconda3/envs/fsd/lib/python3.8/site-packages/keras/engine/training_utils.py", line 141, in standardize_input_data
    raise ValueError(
ValueError: Error when checking target: expected predictions to have shape (2,) but got array with shape (1,)
/var/spool/slurm/d/job05696/slurm_script: line 19: 1060692 Aborted                 (core dumped) python train.py --bs 64 --dim 128 --backbone Xception --num-workers 8
